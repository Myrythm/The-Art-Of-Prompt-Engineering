{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnIEQyWc6i0D",
        "outputId": "be369d0e-09ed-45ef-d363-0ba9c5a162c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.0.18\n",
            "  Downloading langchain-0.0.18-py3-none-any.whl (95 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.9/95.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.18) (2.6.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.18) (2.0.27)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.18) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.18) (2.31.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.18) (6.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->langchain==0.0.18) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->langchain==0.0.18) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->langchain==0.0.18) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->langchain==0.0.18) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->langchain==0.0.18) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->langchain==0.0.18) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->langchain==0.0.18) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->langchain==0.0.18) (3.0.3)\n",
            "Installing collected packages: langchain\n",
            "Successfully installed langchain-0.0.18\n",
            "Collecting pydantic==1.10.9\n",
            "  Downloading pydantic-1.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.9) (4.9.0)\n",
            "Installing collected packages: pydantic\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.1\n",
            "    Uninstalling pydantic-2.6.1:\n",
            "      Successfully uninstalled pydantic-2.6.1\n",
            "Successfully installed pydantic-1.10.9\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.0.18\n",
        "!pip install pydantic==1.10.9\n",
        "#!pip install OpenAI\n",
        "!pip install huggingface-hub\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#from langchain.llms import OpenAI\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "# set up the environment with respected API key\n",
        "#os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "\n",
        "# you can choose between different llm models\n",
        "\n",
        "# The \"temperature\" is a hyperparameter that controls the randomness of the model's output. A lower value (like 0.1) makes the output more deterministic, while a higher value makes it more random.\n",
        "# \"max_new_tokens\" parameter sets a limit on the maximum number of new tokens (words/characters) that the model can generate as output.\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=\"tiiuae/falcon-7b-instruct\",model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 600})\n",
        "\n",
        "\n",
        "# you can use OpenAI GPT models\n",
        "#llm = OpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "\n",
        "text = \"How read book effectively?\"\n",
        "\n",
        "print(llm(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITqDko6y6vko",
        "outputId": "481d4792-25e7-42fc-863d-978c707fe342"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "To read a book effectively, you should start by setting aside a specific time and place for reading. This will help you stay focused and avoid distractions. You should also choose a book that interests you and that you are excited to read. Additionally, try to read in a comfortable position and take breaks as needed. Finally, try to engage with the material by asking questions and making connections to what you already know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#from langchain.llms import OpenAI\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "# set up the environment with respected API key\n",
        "#os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "\n",
        "# you can choose between different llm models\n",
        "\n",
        "# The \"temperature\" is a hyperparameter that controls the randomness of the model's output. A lower value (like 0.1) makes the output more deterministic, while a higher value makes it more random.\n",
        "# \"max_new_tokens\" parameter sets a limit on the maximum number of new tokens (words/characters) that the model can generate as output.\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=\"tiiuae/falcon-7b-instruct\",model_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 600})\n",
        "\n",
        "\n",
        "# you can use OpenAI GPT models\n",
        "#llm = OpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "\n",
        "text = \"How read book effectively?\"\n",
        "\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUuUR9vM9xJj",
        "outputId": "4613869a-9bcb-4677-c19c-2701ffedda96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "To read a book effectively, you should start by setting aside a specific time and place for reading. This will help you stay focused and avoid distractions. You should also choose a book that interests you and that you are excited to read. Additionally, try to read in a comfortable position and take breaks as needed. Finally, try to engage with the material by asking questions and making connections to what you already know.\n"
          ]
        }
      ]
    }
  ]
}